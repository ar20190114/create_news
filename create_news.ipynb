{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mM99gYIxkipW"
      },
      "outputs": [],
      "source": [
        "!pip install -qU torch==1.7.1 torchtext==0.8.0 torchvision==0.8.2\n",
        "!pip install -q transformers==4.4.2 pytorch_lightning==1.2.1 sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2WZ8TSWikva9"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/data /content/model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kikbTUMQlfxK"
      },
      "outputs": [],
      "source": [
        "# 事前学習済みモデル\n",
        "PRETRAINED_MODEL_NAME = \"sonoisa/t5-base-japanese\"\n",
        "\n",
        "# 転移学習済みモデル\n",
        "MODEL_DIR = \"/content/model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFbgENNBlmZP",
        "outputId": "9849793e-37c1-49a2-8f33-27fe7d640e43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-02-18 07:08:48--  https://www.rondhuit.com/download/ldcc-20140209.tar.gz\n",
            "Resolving www.rondhuit.com (www.rondhuit.com)... 59.106.19.174\n",
            "Connecting to www.rondhuit.com (www.rondhuit.com)|59.106.19.174|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8855190 (8.4M) [application/x-gzip]\n",
            "Saving to: ‘ldcc-20140209.tar.gz’\n",
            "\n",
            "ldcc-20140209.tar.g 100%[===================>]   8.44M  1.70MB/s    in 5.0s    \n",
            "\n",
            "2022-02-18 07:08:54 (1.70 MB/s) - ‘ldcc-20140209.tar.gz’ saved [8855190/8855190]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O ldcc-20140209.tar.gz https://www.rondhuit.com/download/ldcc-20140209.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "B4nhMZpdlwd_"
      },
      "outputs": [],
      "source": [
        "# https://github.com/neologd/mecab-ipadic-neologd/wiki/Regexp.ja から引用・一部改変\n",
        "from __future__ import unicode_literals\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def unicode_normalize(cls, s):\n",
        "    pt = re.compile('([{}]+)'.format(cls))\n",
        "\n",
        "    def norm(c):\n",
        "        return unicodedata.normalize('NFKC', c) if pt.match(c) else c\n",
        "\n",
        "    s = ''.join(norm(x) for x in re.split(pt, s))\n",
        "    s = re.sub('－', '-', s)\n",
        "    return s\n",
        "\n",
        "def remove_extra_spaces(s):\n",
        "    s = re.sub('[ 　]+', ' ', s)\n",
        "    blocks = ''.join(('\\u4E00-\\u9FFF',  # CJK UNIFIED IDEOGRAPHS\n",
        "                      '\\u3040-\\u309F',  # HIRAGANA\n",
        "                      '\\u30A0-\\u30FF',  # KATAKANA\n",
        "                      '\\u3000-\\u303F',  # CJK SYMBOLS AND PUNCTUATION\n",
        "                      '\\uFF00-\\uFFEF'   # HALFWIDTH AND FULLWIDTH FORMS\n",
        "                      ))\n",
        "    basic_latin = '\\u0000-\\u007F'\n",
        "\n",
        "    def remove_space_between(cls1, cls2, s):\n",
        "        p = re.compile('([{}]) ([{}])'.format(cls1, cls2))\n",
        "        while p.search(s):\n",
        "            s = p.sub(r'\\1\\2', s)\n",
        "        return s\n",
        "\n",
        "    s = remove_space_between(blocks, blocks, s)\n",
        "    s = remove_space_between(blocks, basic_latin, s)\n",
        "    s = remove_space_between(basic_latin, blocks, s)\n",
        "    return s\n",
        "\n",
        "def normalize_neologd(s):\n",
        "    s = s.strip()\n",
        "    s = unicode_normalize('０-９Ａ-Ｚａ-ｚ｡-ﾟ', s)\n",
        "\n",
        "    def maketrans(f, t):\n",
        "        return {ord(x): ord(y) for x, y in zip(f, t)}\n",
        "\n",
        "    s = re.sub('[˗֊‐‑‒–⁃⁻₋−]+', '-', s)  # normalize hyphens\n",
        "    s = re.sub('[﹣－ｰ—―─━ー]+', 'ー', s)  # normalize choonpus\n",
        "    s = re.sub('[~∼∾〜〰～]+', '〜', s)  # normalize tildes (modified by Isao Sonobe)\n",
        "    s = s.translate(\n",
        "        maketrans('!\"#$%&\\'()*+,-./:;<=>?@[¥]^_`{|}~｡､･｢｣',\n",
        "              '！”＃＄％＆’（）＊＋，－．／：；＜＝＞？＠［￥］＾＿｀｛｜｝〜。、・「」'))\n",
        "\n",
        "    s = remove_extra_spaces(s)\n",
        "    s = unicode_normalize('！”＃＄％＆’（）＊＋，－．／：；＜＞？＠［￥］＾＿｀｛｜｝〜', s)  # keep ＝,・,「,」\n",
        "    s = re.sub('[’]', '\\'', s)\n",
        "    s = re.sub('[”]', '\"', s)\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TVoUbAYel7Zq"
      },
      "outputs": [],
      "source": [
        "import tarfile\n",
        "import re\n",
        "\n",
        "target_genres = [\"dokujo-tsushin\",\n",
        "                 \"it-life-hack\",\n",
        "                 \"kaden-channel\",\n",
        "                 \"livedoor-homme\",\n",
        "                 \"movie-enter\",\n",
        "                 \"peachy\",\n",
        "                 \"smax\",\n",
        "                 \"sports-watch\",\n",
        "                 \"topic-news\"]\n",
        "\n",
        "def remove_brackets(text):\n",
        "    text = re.sub(r\"(^【[^】]*】)|(【[^】]*】$)\", \"\", text)\n",
        "    return text\n",
        "\n",
        "def normalize_text(text):\n",
        "    assert \"\\n\" not in text and \"\\r\" not in text\n",
        "    text = text.replace(\"\\t\", \" \")\n",
        "    text = text.strip()\n",
        "    text = normalize_neologd(text)\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "def read_title_body(file):\n",
        "    next(file)\n",
        "    next(file)\n",
        "    title = next(file).decode(\"utf-8\").strip()\n",
        "    title = normalize_text(remove_brackets(title))\n",
        "    body = normalize_text(\" \".join([line.decode(\"utf-8\").strip() for line in file.readlines()]))\n",
        "    return title, body\n",
        "\n",
        "genre_files_list = [[] for genre in target_genres]\n",
        "\n",
        "all_data = []\n",
        "\n",
        "with tarfile.open(\"ldcc-20140209.tar.gz\") as archive_file:\n",
        "    for archive_item in archive_file:\n",
        "        for i, genre in enumerate(target_genres):\n",
        "            if genre in archive_item.name and archive_item.name.endswith(\".txt\"):\n",
        "                genre_files_list[i].append(archive_item.name)\n",
        "\n",
        "    for i, genre_files in enumerate(genre_files_list):\n",
        "        for name in genre_files:\n",
        "            file = archive_file.extractfile(name)\n",
        "            title, body = read_title_body(file)\n",
        "            title = normalize_text(title)\n",
        "            body = normalize_text(body)\n",
        "\n",
        "            if len(title) > 0 and len(body) > 0:\n",
        "                all_data.append({\n",
        "                    \"title\": title,\n",
        "                    \"body\": body,\n",
        "                    \"genre_id\": i\n",
        "                    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRC9n9Q7mLvb",
        "outputId": "881ccedd-7733-4254-af53-507f6aff1981"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7334it [00:00, 89565.05it/s]\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "random.seed(1234)\n",
        "random.shuffle(all_data)\n",
        "\n",
        "def to_line(data):\n",
        "    title = data[\"title\"]\n",
        "    body = data[\"body\"]\n",
        "    genre_id = data[\"genre_id\"]\n",
        "\n",
        "    assert len(title) > 0 and len(body) > 0\n",
        "    return f\"{title}\\t{body}\\t{genre_id}\\n\"\n",
        "\n",
        "data_size = len(all_data)\n",
        "train_ratio, dev_ratio, test_ratio = 0.9, 0.05, 0.05\n",
        "\n",
        "with open(f\"data/train.tsv\", \"w\", encoding=\"utf-8\") as f_train, \\\n",
        "    open(f\"data/dev.tsv\", \"w\", encoding=\"utf-8\") as f_dev, \\\n",
        "    open(f\"data/test.tsv\", \"w\", encoding=\"utf-8\") as f_test:\n",
        "    \n",
        "    for i, data in tqdm(enumerate(all_data)):\n",
        "        line = to_line(data)\n",
        "        if i < train_ratio * data_size:\n",
        "            f_train.write(line)\n",
        "        elif i < (train_ratio + dev_ratio) * data_size:\n",
        "            f_dev.write(line)\n",
        "        else:\n",
        "            f_test.write(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9uiiZOMmRFw",
        "outputId": "7e94323e-570b-42fc-f8f0-d8adf649b4ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "別れる?続ける?3月末で決断を迫る査定サービス\t3月に入り、世間は卒業シーズン真っ只中。誰もが経験したことのある“別れ\"の季節だけに寂しさも感じるが、その先にある新たな出会いにも心躍らせる季節ともいえる。社会人でも転勤や異動など、人の入れ替わりや案件の整理など、とにかく「忙しい」というイメージが先行してしまいがちなのが年度末。さらには、予算消化の道路工事が各所で行われる光景もまた、気忙しくさせる原因でもある。年度末といえば、課税標準の時期でもある。住民税も所得税も車両税も、すべてその年の3月末を起点として算出される。つまり「クルマを持っているとお金が掛かる」ことを最も実感する時期でもあるのだ。そしてクルマ関連でもうひとつ、年度末のこの時期にこそ注目してほしいことがある。それは「年度末はクルマの売買が最も盛んな時期」ということ。下記のグラフを見れば一目瞭然の事実。3月の自動車登録台数は、他の月の2倍近い数字を記録している。これは、先述のとおり課税時期であること、そして自動車ディーラー等で大規模なキャンペーンを行うためだ。こんな時期だからこそ、クルマ乗換ようかな?売ろうかな?と悩む人も多いだろう。その前に、まずは愛車の買取相場を調べてみてはいかがだろうか?愛車が今いくらなのか、現在価格を正確に知っておことは、この重要な時期の大切な情報と言える。そこで、オススメするのは、日本最大規模の中古車査定ネットワークを誇るカービューの「愛車無料査定」だ。この「愛車無料査定」は、無料サービスでありながら、業界最大規模の査定データベースによって、車の買取相場がオンライン上で分かると同時に、複数社の買取店に見積りを依頼することが出来る。インターネットからサイトにアクセスし査定したい車種と郵便番号、さらには車種情報などを入力すれば、登録地域の買取店、最大8社の査定を比較することが出来る。申込み時間は約3分程度と、とても便利なサービスなのだ。3月という節目の季節。愛車とも「そろそろお別れか」と考えてみても、判断が難しいだろう。悩む前に愛車の現在価格を調べることをオススメする。・あなたの愛車、今いくら?webで買取相場をチェック!・自動車総合サイトcarview.co.jp「愛車無料査定」\t3\n",
            "イベント作成や友人の紹介方法facebook活用のスゴ技・裏技テクニック集\t最近では仕事での付き合いから、facebookアカウントを交換することが増えてきた。周囲がやってるからと始めてみたのはいいんだが、さっぱり使いこなせていない。facebookを使いこなしているかどうかが、“仕事ができるかできないか\"といったことにつながるような気がして、見栄えを良くしてみたりと、いろいろいじっている。その参考にしているのが【知っ得!虎の巻】で紹介してきたfacebook活用術だ。前回のまとめから、さらにテクニックが追加されたのでアップデートということで紹介しよう。イベント作成方法やfacebookで広げる友達の輪、写真を見せたい人だけに見せる方法、公開したことを知らせる方法、間違えてしちゃったコメントをないことにする赤っ恥からのカバー術など盛りだくさんだ。 ■同窓会や女子会で大活躍!facebookで簡単イベント作成【知っ得!虎の巻】facebookのグループで、みんなでどこかに集まって会を開きたいという場合は、イベント機能を利用してみよう。メンバー全員にいっせいにお知らせを出せるし、出欠の確認だって取れる。すべてfacebook内でやり取りできるのでオススメだ。同窓会や女子会で活用してみよう。 ■同じ趣味の人を紹介し合おうfacebookで広げる友達の輪【知っ得!虎の巻】facebookでは友達と友達がつながって、だんだんと大きなつながりができていく。自分の友達の中で、お互い知っているのにまだ友達になっていない人がいたり、趣味とかが同じで話が合いそうなので教えてあげたいな、と思う人がいる場合は、紹介してあげてはどうだろう。 ■仲間内だけでヒミツの会話facebookのグループ機能【知っ得!虎の巻】facebookには、「グループ」という機能がある。グループは、メンバー同士が共通の話題について話し合うことができるスペースだ。興味のある話題で盛り上がろう。また、グループは公開、非公開の他、秘密など、公開範囲を設定できるので、仕事上のやり取りにだって使える。 ■納得いかない写真は見せない!facebookのタグ付き写真は承認する【知っ得!虎の巻】facebookでは、写真に友達をタグ付けすることで、そこに写っているのが誰なのかを表すことができる。タグ付けされた投稿は、相手先のタイムラインにも表示されるが、変な顔で写っていたりなどして、表示させたくない場合もあるだろう。タグ付けされた際に承認、非承認を選択することができるように設定できるので、気になる人は設定しておこう。 ■写真に友達のタグを付けて公開を知らせるfacebookテクニック【知っ得!虎の巻】友達とシェアしたい写真をfacebookにアップしたら、相手にも気づいてほしい!1人や2人なら、それぞれに連絡を入れてもそれほど手間ではないが、人数が増えるとそれもたいへんだ。そんなときには、友達の情報を写真のタグとして貼り付けてみよう。 ■facebookで友達宛にコメントを付けたことを知らせたい【知っ得!虎の巻】facebookで友達の投稿にみんなでコメントを付けているとき、その中で、投稿した友達以外の友達宛に、絶対見てもらいたいコメントがあるときはどうしたらいいだろう。普通に入力したのでは、相手が気づかないこともある。そんなときは、タグ付けの機能を利用しよう。 ■微妙な知り合いからの友達申請に有効なfacebookワザ【知っ得!虎の巻】facebookを利用していると、いろんな人から友達申請が来る。中には仕事上のつきあいの人だったり、ちょっとした知り合い程度の人もいるだろう。申請を断るのはなんだけど、気軽なやりとりまでは見せたくないし、どうしようなんて困ることもあるはず。そんな時に役立つワザを紹介しよう。 ■facebookのコメントを読みやすく!文の途中で改行するワザ【知っ得!虎の巻】友達の投稿にコメントするのに、ずらずらと文章を続けて入力するのでは読みにくくなってしまう。長い文章を入力するのなら、途中で改行した方が絶対分かりやすい。とはいえ、通常の文書入力の時のように、[enter]キーを押したらその時点で投稿されてしまう。実はコメント欄で改行するには、ちょっとしたコツがあるのだ。 ■投稿によって公開範囲を決めたい人のfacebookワザ【知っ得!虎の巻】facebookの投稿は、そのままだとプライバシー設定の範囲に公開される。でも、投稿の内容によっては、広くみんなに伝えたい場合や、逆にもっと絞って特に親しい友達にだけ公開したいという場合もあるだろう。今回は投稿時に公開先を設定する方法を紹介する。 ■間違えてコメントしちゃった!をないことにするfacebookワザ【知っ得!虎の巻】友達の投稿にコメントしようとして、ついうっかり入力ミスをしたまま[enter]キーを押しちゃって投稿しちゃった、なんてことないだろうか?そんな時にも安心。ミスにすぐに気づいたのなら、内容を修正することができるのだ。 ■友達管理が簡単に!facebookで新しいリストを作成する【知っ得!虎の巻】先週、。友達を[親しい友達]リストに登録して、投稿を絞り込む方法を紹介した。しかし、すべての友達をこのリストに入れてしまったら、絞り込んでもかなりの数の投稿が並んでしまい、あまり意味がなくなってしまうことも。そんな時は、新たに自分でリストを作成しよう。 ■個性派facebookにしよう!みんなと違う背景にする方法【知っ得!虎の巻】facebookのタイムラインページはみんな同じ感じでちょっとつまらないなぁなんて思っていないだろうか。プロフィール写真だけでは自分をアピールしきれない!というのなら、背景に「カバー」を追加するといいだろう。 ■大切な投稿を見逃さないfacebookに親友の投稿だけを表示する【知っ得!虎の巻】友達がたくさんいたり、「いいね!」を登録してある企業ページがたくさんあると、ニュースフィードには情報がいっぱいで、つい親友の投稿を見逃してしまったりなんてこともおこってくる。そんな時、ある特定の友達だけの投稿を表示させる方法がある。 ■pc便利技が満載!「知っ得!虎の巻」ブログ ■「知っ得!虎の巻」の記事をもっとみる・firefoxの超簡単ブックマーク登録ワザ・1ページに表示する投稿数を読みやすく調整するtumblrワザ・wordで表の列幅や行幅をピッタリ微調整する・仲間内だけでヒミツの会話facebookのグループ機能・オリジナルのままじゃつまらない!ひと手間加えてtumblrのデザインを変更する\t1\n",
            "nttドコモ、android 4.0 ics搭載3.4インチスマホ「aquos phone st sh-07d」を発表!1ghzcpuや防水、防塵、ワンセグに対応\taquos phone st sh-07dが発表!nttドコモは16日、今夏に発売する予定の新モデルや新しく開始するサービスなどを発表する「2012年夏モデル新商品・新サービス発表会」を開催し、1ghzcpuや防水、ワンセグなどに対応したandroid 4.0(開発コード名:icecream sandwich;ics)」を採用した3.4インチの「aquos phone st sh-07d」(シャープ製)を発表しています。発売時期は2012年6月を予定しています。 ■ 主なスペック機種名aquos st sh-07d発売時期2012年6月サイズ(約mm)107×54×11.9重量(約)108g連続通話3g(約分)340 gsm(約分)390連続待受lte(約時間)-3g(約時間)460 gsm(約時間)330ディスプレイサイズ(インチ)3.4種類newモバイルasv液晶解像度fwvga発色数(色)26万アウトカメラ8.0mインカメラ-チップセットmsm8255 cpuクロック数1.0ghzコア数single ram 1gb rom 4gb外部メモリーmicrosdhcバッテリー(容量mah)1520急速充電-os android 4.0指紋センサー-防水ipx5、7防塵ip5xおサイフケータイ ◯ ワンセグ ◯ gsm ◯ lte(xi)-赤外線 ◯ gps ◯ dlna ◯ mhl ◯ おくだけ充電 ◯ bluetooth 3.0テザリング(最大同時接続数) ◯(5台)nottv(連続視聴時間約分)-simカードmicrosim本体色lime red black記事執筆:s-max編集部 ■関連リンク・エスマックス(s-max)・エスマックス(s-max)smaxjp on twitter・aquos phone sv sh-10d|製品|nttドコモ\t6\n"
          ]
        }
      ],
      "source": [
        "!head -3 data/test.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "utPlkfkbnNMu"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import glob\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import logging\n",
        "import random\n",
        "import re\n",
        "from itertools import chain\n",
        "from string import punctuation\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "\n",
        "# 乱数シードの設定\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NToOmMQBnX99"
      },
      "outputs": [],
      "source": [
        "# GPU利用有無\n",
        "USE_GPU = torch.cuda.is_available()\n",
        "\n",
        "# 各種ハイパーパラメータ\n",
        "args_dict = dict(\n",
        "    data_dir=\"/content/data\",  # データセットのディレクトリ\n",
        "    model_name_or_path=PRETRAINED_MODEL_NAME,\n",
        "    tokenizer_name_or_path=PRETRAINED_MODEL_NAME,\n",
        "\n",
        "    learning_rate=3e-4,\n",
        "    weight_decay=0.0,\n",
        "    adam_epsilon=1e-8,\n",
        "    warmup_steps=0,\n",
        "    gradient_accumulation_steps=1,\n",
        "\n",
        "    # max_input_length=64,\n",
        "    # max_target_length=512,\n",
        "    # train_batch_size=8,\n",
        "    # eval_batch_size=8,\n",
        "    # num_train_epochs=10,\n",
        "\n",
        "    n_gpu=1 if USE_GPU else 0,\n",
        "    early_stop_callback=False,\n",
        "    fp_16=False,\n",
        "    opt_level='O1',\n",
        "    max_grad_norm=1.0,\n",
        "    seed=42,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IDaMLU-InhIP"
      },
      "outputs": [],
      "source": [
        "class TsvDataset(Dataset):\n",
        "    def __init__(self, tokenizer, data_dir, type_path, input_max_len=512, target_max_len=512):\n",
        "        self.file_path = os.path.join(data_dir, type_path)\n",
        "        \n",
        "        self.input_max_len = input_max_len\n",
        "        self.target_max_len = target_max_len\n",
        "        self.tokenizer = tokenizer\n",
        "        self.inputs = []\n",
        "        self.targets = []\n",
        "\n",
        "        self._build()\n",
        "  \n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "  \n",
        "    def __getitem__(self, index):\n",
        "        source_ids = self.inputs[index][\"input_ids\"].squeeze()\n",
        "        target_ids = self.targets[index][\"input_ids\"].squeeze()\n",
        "\n",
        "        source_mask = self.inputs[index][\"attention_mask\"].squeeze()\n",
        "        target_mask = self.targets[index][\"attention_mask\"].squeeze()\n",
        "\n",
        "        return {\"source_ids\": source_ids, \"source_mask\": source_mask, \n",
        "                \"target_ids\": target_ids, \"target_mask\": target_mask}\n",
        "\n",
        "    def _make_record(self, title, body, genre_id):\n",
        "        # ニュースタイトル生成タスク用の入出力形式に変換する。\n",
        "        input = f\"{title}\"\n",
        "        target = f\"{body}\"\n",
        "        return input, target\n",
        "\n",
        "    def _build(self):\n",
        "        with open(self.file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            for line in f:\n",
        "                line = line.strip().split(\"\\t\")\n",
        "                assert len(line) == 3\n",
        "                assert len(line[0]) > 0\n",
        "                assert len(line[1]) > 0\n",
        "                assert len(line[2]) > 0\n",
        "\n",
        "                title = line[0]\n",
        "                body = line[1]\n",
        "                genre_id = line[2]\n",
        "\n",
        "                input, target = self._make_record(title, body, genre_id)\n",
        "\n",
        "                tokenized_inputs = self.tokenizer.batch_encode_plus(\n",
        "                    [input], max_length=self.input_max_len, truncation=True, \n",
        "                    padding=\"max_length\", return_tensors=\"pt\"\n",
        "                )\n",
        "\n",
        "                tokenized_targets = self.tokenizer.batch_encode_plus(\n",
        "                    [target], max_length=self.target_max_len, truncation=True, \n",
        "                    padding=\"max_length\", return_tensors=\"pt\"\n",
        "                )\n",
        "\n",
        "                self.inputs.append(tokenized_inputs)\n",
        "                self.targets.append(tokenized_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3-tcV3XunsbU"
      },
      "outputs": [],
      "source": [
        "# トークナイザー（SentencePiece）モデルの読み込み\n",
        "tokenizer = T5Tokenizer.from_pretrained(PRETRAINED_MODEL_NAME, is_fast=True)\n",
        "\n",
        "# テストデータセットの読み込み\n",
        "train_dataset = TsvDataset(tokenizer, args_dict[\"data_dir\"], \"train.tsv\", \n",
        "                           input_max_len=64, target_max_len=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3LrndAjn4Z1",
        "outputId": "fbada5cc-c179-4eff-9f39-ddefef428634"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A. 入力データの元になる文字列\n",
            "hulu、ついに待望のapple tvに対応!一周年記念で「huluアンバサダープロジェクト」もスタート</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "\n",
            "B. 入力データ（Aの文字列がトークナイズされたトークンID列）\n",
            "tensor([21105,  4763,     3,  5057,  3888,  1798,     6, 21868, 15594,  6477,\n",
            "          253,    82,  6838,    15,    19, 10654,  4763,   500,   206,   211,\n",
            "          626,  1318,    17,    28,  2330,     1,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n",
            "\n",
            "C. 出力データの元になる文字列\n",
            "huluは昨年9月にサービスを開始して以来、日本でのビジネスを順調に拡大してきた。現在は約1000本の映画と、10,000話以上に及ぶテレビ番組の視聴が可能だ。そんなhuluから新たなニュースが飛び込んできた。 ■今日からapple tvに対応!今日、9月4日から新たに「apple tv」にてhuluを楽しめるようになったという。aple idを用いて新規登録や決済も可能だという。apple tvのホーム画面からhuluを起動し、すでにアカウントを持っているユーザーはログイン。また、まだアカウントを持っていない人も簡単にitunesアカウントで登録できる。apple tvより新規登録したユーザーは通常2週間の無料トライアルが1ヶ月になるということだ。 ■サービス一周年記念「huluアンバサダープロジェクト」9月12日からサービス一周年を記念したスペシャルプロジェクト「huluアンバサダープロジェクト」が実施される。facebookやtwitterを通してhuluについて情報発信すると「huluアンバサダー」に任命され、先着10,000名の新規登録者は1ケ月無料トライアルが楽しめるということだ。コンテンツも対応デバイスもますます増えるhuluに今後も注目だ。</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "\n",
            "D. 出力データ（Cの文字列がトークナイズされたトークンID列）\n",
            "tensor([21105,  4763,     7, 11708,    12,    50,   133,   710,  4397, 20082,\n",
            "            3, 11666,  3259,    14, 15134,  1915,  2107,     4,  1190,   216,\n",
            "         1961,  2819,   246,    16,     3, 21366,   388,   790,  7279,  4983,\n",
            "            6,  9927,  4190,   317,     4,  9817, 10654,  4763,    24,  1454,\n",
            "         1428,     8,  4598,  3713,  2239,     4,     5, 26488,  4634,    24,\n",
            "        21868, 15594,  6477,   253,  4634,     3,    50,    18,    31,   573,\n",
            "         1922,    19, 21868, 15594,    17,   244, 10654,  4763,    14, 17181,\n",
            "         1176,    47,     4,    96, 12306,     5,  2204,  2383,  3706,  1313,\n",
            "           22, 19993, 11187,  6063,     4, 21868, 15594,     6,   814,  2811,\n",
            "           24, 10654,  4763,    14, 11020,    29,     3,  3082,  7155,  3520,\n",
            "         2441,     7, 25304,     4,   238,     3,  2289,  7155,  4317,  2069,\n",
            "        11549,  9322, 25522,  7155,    15,  1313,   348,     4, 21868, 15594,\n",
            "           89,  3706,  1313,    27,  2441,  6707,    20,  2603,     6,  4210,\n",
            "        17370,     8,    21,  2123,   365,  3320,   317,     4,     5, 26488,\n",
            "          710,    82,  6838,    19, 10654,  4763,   500,   206,   211,   626,\n",
            "         1318,    17,    50,    18,    63,   573,   710,    82, 30756,    38,\n",
            "         2701,  1318,    19, 10654,  4763,   500,   206,   211,   626,  1318,\n",
            "           17,     8, 19022,     4, 25219,    22, 13316,  3477, 10654,  4763,\n",
            "          240,   517, 10335,   412,    19, 10654,  4763,   500,   206,   211,\n",
            "          626,    17, 12430,     3,   544,   451, 21366,  2235,  3706,  1313,\n",
            "         1680,    21,   401,    18,  4210, 17370,     8, 17181,  3320,   317,\n",
            "            4,  6485,    28,  1246, 12126,    28, 20373,  8275,    55, 10654,\n",
            "         4763,    13,  5572,    28,  8049,   317,     4,     1,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n"
          ]
        }
      ],
      "source": [
        "for data in train_dataset:\n",
        "    print(\"A. 入力データの元になる文字列\")\n",
        "    print(tokenizer.decode(data[\"source_ids\"]))\n",
        "    print()\n",
        "    print(\"B. 入力データ（Aの文字列がトークナイズされたトークンID列）\")\n",
        "    print(data[\"source_ids\"])\n",
        "    print()\n",
        "    print(\"C. 出力データの元になる文字列\")\n",
        "    print(tokenizer.decode(data[\"target_ids\"]))\n",
        "    print()\n",
        "    print(\"D. 出力データ（Cの文字列がトークナイズされたトークンID列）\")\n",
        "    print(data[\"target_ids\"])\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RvhEbU7OonYG"
      },
      "outputs": [],
      "source": [
        "class T5FineTuner(pl.LightningModule):\n",
        "    def __init__(self, hparams):\n",
        "        super().__init__()\n",
        "        self.hparams = hparams\n",
        "\n",
        "        # 事前学習済みモデルの読み込み\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained(hparams.model_name_or_path)\n",
        "\n",
        "        # トークナイザーの読み込み\n",
        "        self.tokenizer = T5Tokenizer.from_pretrained(hparams.tokenizer_name_or_path, is_fast=True)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, decoder_input_ids=None, \n",
        "                decoder_attention_mask=None, labels=None):\n",
        "        \"\"\"順伝搬\"\"\"\n",
        "        return self.model(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            decoder_input_ids=decoder_input_ids,\n",
        "            decoder_attention_mask=decoder_attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "    def _step(self, batch):\n",
        "        \"\"\"ロス計算\"\"\"\n",
        "        labels = batch[\"target_ids\"]\n",
        "\n",
        "        # All labels set to -100 are ignored (masked), \n",
        "        # the loss is only computed for labels in [0, ..., config.vocab_size]\n",
        "        labels[labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
        "\n",
        "        outputs = self(\n",
        "            input_ids=batch[\"source_ids\"],\n",
        "            attention_mask=batch[\"source_mask\"],\n",
        "            decoder_attention_mask=batch['target_mask'],\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        loss = outputs[0]\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "          \"\"\"訓練ステップ処理\"\"\"\n",
        "          loss = self._step(batch)\n",
        "          self.log(\"train_loss\", loss)\n",
        "          return {\"loss\": loss}\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        \"\"\"バリデーションステップ処理\"\"\"\n",
        "        loss = self._step(batch)\n",
        "        self.log(\"val_loss\", loss)\n",
        "        return {\"val_loss\": loss}\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        \"\"\"テストステップ処理\"\"\"\n",
        "        loss = self._step(batch)\n",
        "        self.log(\"test_loss\", loss)\n",
        "        return {\"test_loss\": loss}\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"オプティマイザーとスケジューラーを作成する\"\"\"\n",
        "        model = self.model\n",
        "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "        optimizer_grouped_parameters = [\n",
        "            {\n",
        "                \"params\": [p for n, p in model.named_parameters() \n",
        "                            if not any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": self.hparams.weight_decay,\n",
        "            },\n",
        "            {\n",
        "                \"params\": [p for n, p in model.named_parameters() \n",
        "                            if any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": 0.0,\n",
        "            },\n",
        "        ]\n",
        "        optimizer = AdamW(optimizer_grouped_parameters, \n",
        "                          lr=self.hparams.learning_rate, \n",
        "                          eps=self.hparams.adam_epsilon)\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer, num_warmup_steps=self.hparams.warmup_steps, \n",
        "            num_training_steps=self.t_total\n",
        "        )\n",
        "        self.scheduler = scheduler\n",
        "\n",
        "        return [optimizer], [{\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1}]\n",
        "\n",
        "    def get_dataset(self, tokenizer, type_path, args):\n",
        "        \"\"\"データセットを作成する\"\"\"\n",
        "        return TsvDataset(\n",
        "            tokenizer=tokenizer, \n",
        "            data_dir=args.data_dir, \n",
        "            type_path=type_path, \n",
        "            input_max_len=args.max_input_length,\n",
        "            target_max_len=args.max_target_length)\n",
        "      \n",
        "    def setup(self, stage=None):\n",
        "        \"\"\"初期設定（データセットの読み込み）\"\"\"\n",
        "        if stage == 'fit' or stage is None:\n",
        "            train_dataset = self.get_dataset(tokenizer=self.tokenizer, \n",
        "                                            type_path=\"train.tsv\", args=self.hparams)\n",
        "            self.train_dataset = train_dataset\n",
        "\n",
        "            val_dataset = self.get_dataset(tokenizer=self.tokenizer, \n",
        "                                          type_path=\"dev.tsv\", args=self.hparams)\n",
        "            self.val_dataset = val_dataset\n",
        "\n",
        "            self.t_total = (\n",
        "                (len(train_dataset) // (self.hparams.train_batch_size * max(1, self.hparams.n_gpu)))\n",
        "                // self.hparams.gradient_accumulation_steps\n",
        "                * float(self.hparams.num_train_epochs)\n",
        "            )\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        \"\"\"訓練データローダーを作成する\"\"\"\n",
        "        return DataLoader(self.train_dataset, \n",
        "                          batch_size=self.hparams.train_batch_size, \n",
        "                          drop_last=True, shuffle=True, num_workers=4)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        \"\"\"バリデーションデータローダーを作成する\"\"\"\n",
        "        return DataLoader(self.val_dataset, \n",
        "                          batch_size=self.hparams.eval_batch_size, \n",
        "                          num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kR9lD4-UpPhB"
      },
      "outputs": [],
      "source": [
        "# 学習に用いるハイパーパラメータを設定する\n",
        "args_dict.update({\n",
        "    \"max_input_length\":  64,  # 入力文の最大トークン数\n",
        "    \"max_target_length\": 512,  # 出力文の最大トークン数\n",
        "    \"train_batch_size\":  8,\n",
        "    \"eval_batch_size\":   8,\n",
        "    \"num_train_epochs\":  10,\n",
        "    })\n",
        "args = argparse.Namespace(**args_dict)\n",
        "\n",
        "train_params = dict(\n",
        "    accumulate_grad_batches=args.gradient_accumulation_steps,\n",
        "    gpus=args.n_gpu,\n",
        "    max_epochs=args.num_train_epochs,\n",
        "    precision= 16 if args.fp_16 else 32,\n",
        "    amp_level=args.opt_level,\n",
        "    gradient_clip_val=args.max_grad_norm,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "iIdNs5nDpS6H",
        "outputId": "925bd3af-3a9b-4d08-a085-dd9c99ed90a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: None, using: 0 TPU cores\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-05f395e0cc01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT5FineTuner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 最終エポックのモデルを保存\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;31m# SET UP TRAINING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_setup_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_before_accelerator_backend_setup\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mcall_setup_hook\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m   1070\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatamodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_reset_result_and_set_hook_fx_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-9e4c654a4704>\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             val_dataset = self.get_dataset(tokenizer=self.tokenizer, \n\u001b[0;32m--> 105\u001b[0;31m                                           type_path=\"dev.tsv\", args=self.hparams)\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-9e4c654a4704>\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(self, tokenizer, type_path, args)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtype_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0minput_max_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_input_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             target_max_len=args.max_target_length)\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-619ebd4feeef>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tokenizer, data_dir, type_path, input_max_len, target_max_len)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-619ebd4feeef>\u001b[0m in \u001b[0;36m_build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 tokenized_targets = self.tokenizer.batch_encode_plus(\n\u001b[1;32m     53\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_max_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                     \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                 )\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2449\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2450\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2451\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2452\u001b[0m         )\n\u001b[1;32m   2453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mids_or_pair_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mfirst_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0msecond_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpair_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 転移学習の実行（GPUを利用すれば1エポック10分程度）\n",
        "model = T5FineTuner(args)\n",
        "trainer = pl.Trainer(**train_params)\n",
        "trainer.fit(model)\n",
        "\n",
        "# 最終エポックのモデルを保存\n",
        "model.tokenizer.save_pretrained(MODEL_DIR)\n",
        "model.model.save_pretrained(MODEL_DIR)\n",
        "\n",
        "del model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOEelZOWrHaS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "\n",
        "# トークナイザー（SentencePiece）\n",
        "tokenizer = T5Tokenizer.from_pretrained(MODEL_DIR, is_fast=True)\n",
        "\n",
        "# 学習済みモデル\n",
        "trained_model = T5ForConditionalGeneration.from_pretrained(MODEL_DIR)\n",
        "\n",
        "# GPUの利用有無\n",
        "USE_GPU = torch.cuda.is_available()\n",
        "if USE_GPU:\n",
        "    trained_model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9NjDwiBrPOM"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn import metrics\n",
        "\n",
        "# テストデータの読み込み\n",
        "test_dataset = TsvDataset(tokenizer, args_dict[\"data_dir\"], \"test.tsv\", \n",
        "                          input_max_len=args.max_input_length, \n",
        "                          target_max_len=args.max_target_length)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, num_workers=4)\n",
        "\n",
        "trained_model.eval()\n",
        "\n",
        "inputs = []\n",
        "outputs = []\n",
        "targets = []\n",
        "\n",
        "for batch in tqdm(test_loader):\n",
        "    input_ids = batch['source_ids']\n",
        "    input_mask = batch['source_mask']\n",
        "    if USE_GPU:\n",
        "        input_ids = input_ids.cuda()\n",
        "        input_mask = input_mask.cuda()\n",
        "\n",
        "    output = trained_model.generate(input_ids=input_ids, \n",
        "        attention_mask=input_mask, \n",
        "        max_length=args.max_target_length,\n",
        "        repetition_penalty=10.0,   # 同じ文の繰り返し（モード崩壊）へのペナルティ\n",
        "        )\n",
        "\n",
        "    output_text = [tokenizer.decode(ids, skip_special_tokens=True, \n",
        "                            clean_up_tokenization_spaces=False) \n",
        "                for ids in output]\n",
        "    target_text = [tokenizer.decode(ids, skip_special_tokens=True, \n",
        "                               clean_up_tokenization_spaces=False) \n",
        "                for ids in batch[\"target_ids\"]]\n",
        "    input_text = [tokenizer.decode(ids, skip_special_tokens=True, \n",
        "                               clean_up_tokenization_spaces=False) \n",
        "                for ids in input_ids]\n",
        "\n",
        "    inputs.extend(input_text)\n",
        "    outputs.extend(output_text)\n",
        "    targets.extend(target_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zBCdXQ7rXt6"
      },
      "outputs": [],
      "source": [
        "for output, target, input in zip(outputs, targets, inputs):\n",
        "    print(\"title:     \" + input)\n",
        "    print(\"generated: \" + output)\n",
        "    print(\"actual:    \" + target)\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmBTXQMrrbeq"
      },
      "outputs": [],
      "source": [
        "title = \"LEGOで作るスマートロック　〜「Hey Siri 鍵開けて」を実現する方法 〜\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeaujpSwreqi"
      },
      "outputs": [],
      "source": [
        "MAX_SOURCE_LENGTH = args.max_input_length   # 入力される記事本文の最大トークン数\n",
        "MAX_TARGET_LENGTH = args.max_target_length  # 生成されるタイトルの最大トークン数\n",
        "\n",
        "def preprocess_title(text):\n",
        "    return normalize_text(text.replace(\"\\n\", \"\"))\n",
        "\n",
        "# 推論モード設定\n",
        "trained_model.eval()\n",
        "\n",
        "# 前処理とトークナイズを行う\n",
        "inputs = [preprocess_title(title)]\n",
        "batch = tokenizer.batch_encode_plus(\n",
        "    inputs, max_length=MAX_SOURCE_LENGTH, truncation=True, \n",
        "    padding=\"longest\", return_tensors=\"pt\")\n",
        "\n",
        "input_ids = batch['input_ids']\n",
        "input_mask = batch['attention_mask']\n",
        "if USE_GPU:\n",
        "    input_ids = input_ids.cuda()\n",
        "    input_mask = input_mask.cuda()\n",
        "\n",
        "# 生成処理を行う\n",
        "outputs = trained_model.generate(\n",
        "    input_ids=input_ids, attention_mask=input_mask, \n",
        "    max_length=MAX_TARGET_LENGTH,\n",
        "    # temperature=1.0,  # 生成にランダム性を入れる温度パラメータ\n",
        "    # num_beams=10,  # ビームサーチの探索幅\n",
        "    # diversity_penalty=1.0,  # 生成結果の多様性を生み出すためのペナルティパラメータ\n",
        "    # num_beam_groups=10,  # ビームサーチのグループ\n",
        "    # num_return_sequences=10,  # 生成する文の数\n",
        "    repetition_penalty=8.0,   # 同じ文の繰り返し（モード崩壊）へのペナルティ\n",
        ")\n",
        "\n",
        "# 生成されたトークン列を文字列に変換する\n",
        "generated_bodies = [tokenizer.decode(ids, skip_special_tokens=True, \n",
        "                                     clean_up_tokenization_spaces=False) \n",
        "                    for ids in outputs]\n",
        "\n",
        "# 生成された文章を表示する\n",
        "for i, body in enumerate(generated_bodies):\n",
        "    print(\"\\n\".join(textwrap.wrap(f\"{i+1:2}. {body}\")))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "create_news.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
